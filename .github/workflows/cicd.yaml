name: CI/CD Pipeline

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]

jobs:
  train:
    name: train (Continuous Integration)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Training Script
        run: |
          mkdir -p output
          python Script/train.py

      - name: Capture Metrics
        id: capture_metrics
        run: |
          # Read accuracy from metrics.json (last entry)
          METRIC=$(jq -r '.[-1]."accuracy"' output/metrics.json)
          echo "metric=$METRIC" >> $GITHUB_OUTPUT
          echo "Current Accuracy captured: $METRIC"

      - name: Prepare Artifacts
        run: |
          mkdir -p training-artifacts-py3.11
          cp output/model-linear-exp1.pkl training-artifacts-py3.11/
          cp output/metrics.json training-artifacts-py3.11/

      - name: Upload Model and Metrics
        uses: actions/upload-artifact@v4
        with:
          name: model-artifacts
          path: training-artifacts-py3.11/

  deploy:
    name: deploy (Continuous Deployment)
    needs: train
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download Artifacts
        uses: actions/download-artifact@v4
        with:
          name: model-artifacts
          path: training-artifacts-py3.11/

      - name: Compare Metrics
        id: compare
        env:
          BEST_METRIC: ${{ vars.BEST_Metric || 0 }}
        run: |
          python -c "
          import json, os, sys
          
          with open('training-artifacts-py3.11/metrics.json', 'r') as f:
              data = json.load(f)
          
          current_metric = float(data[-1]['accuracy'])
          best_metric = float(os.environ.get('BEST_METRIC', 0))
          
          print(f'Current Accuracy: {current_metric}')
          print(f'Best Accuracy: {best_metric}')
          
          if current_metric > best_metric:
              print('Metric improved!')
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f'improved=true\nnew_best_metric={current_metric}\n')
          else:
              print('2022BCD0013----Metric did not improve')
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write('improved=false\n')
              sys.exit(1)
          "

      - name: Login to Docker Hub
        if: steps.compare.outputs.improved == 'true'
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build and Publish Image
        if: steps.compare.outputs.improved == 'true'
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./dockerfile
          push: true
          tags: ${{ secrets.DOCKERHUB_USERNAME }}/wine-quality-app:latest

     
